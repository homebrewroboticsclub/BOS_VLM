# BOS_VLM: Visual Language Models for Brew Operating System

A lightweight, easy-to-use package for integrating visual language models with the Brew Operating System.

## Features

- Simple interface for multiple visual language models (CLIP, OWL-ViT, etc.)
- BOS topics for image inputs and language outputs
- Support for real-time inference on robot camera feeds
- Modular design for easy extension to new models
- Prebuilt Docker container for hassle-free setup
- Built-in support for common robotics tasks:
  - Visual question answering
  - Object grounding
  - Scene description
  - Visual reasoning

## Directory Structure

```
ðŸ“¦ BOS_VLM
 â”£ ðŸ“‚ BOS_VLM                     # Main package
 â”ƒ  â”£ __init__.py
 â”ƒ  â”£ ðŸ“‚ models                   # Model implementations
 â”ƒ  â”ƒ  â”£ __init__.py
 â”ƒ  â”ƒ  â”£ base_model.py            # Abstract base class
 â”ƒ  â”ƒ  â”£ clip_model.py
 â”ƒ  â”ƒ  â”£ owlvit_model.py
 â”ƒ  â”ƒ  â”— ...
 â”ƒ  â”£ ðŸ“‚ bos                      # BOS integration
 â”ƒ  â”ƒ  â”£ __init__.py
 â”ƒ  â”ƒ  â”£ node.py                  # Main BOS node
 â”ƒ  â”ƒ  â”£ topics.py                # Topic definitions
 â”ƒ  â”ƒ  â”— utils.py
 â”ƒ  â”— ðŸ“‚ utils
 â”ƒ     â”£ __init__.py
 â”ƒ     â”£ image_processing.py
 â”ƒ     â”— text_processing.py
 â”£ ðŸ“‚ config                      # Configuration files
 â”ƒ  â”£ default.yaml                # Default configuration
 â”ƒ  â”— ðŸ“‚ models                   # Model-specific configurations
 â”ƒ     â”£ clip.yaml
 â”ƒ     â”— owlvit.yaml
 â”£ ðŸ“‚ launch                      # BOS launch files
 â”ƒ  â”£ vlm_node.launch
 â”ƒ  â”— demo.launch
 â”£ ðŸ“‚ scripts                     # Utility scripts
 â”ƒ  â”£ download_models.sh
 â”ƒ  â”— benchmark.py
 â”£ ðŸ“‚ examples                    # Usage examples
 â”ƒ  â”£ simple_query.py
 â”ƒ  â”£ object_detection.py
 â”ƒ  â”— interactive_demo.py
 â”£ ðŸ“‚ tests                       # Unit and integration tests
 â”ƒ  â”£ test_models.py
 â”ƒ  â”— test_bos_integration.py
 â”£ ðŸ“‚ docs                        # Documentation
 â”ƒ  â”£ installation.md
 â”ƒ  â”£ models.md
 â”ƒ  â”£ bos_integration.md
 â”ƒ  â”— examples.md
 â”£ Dockerfile                     # Docker setup
 â”£ setup.py                       # Package setup
 â”£ requirements.txt               # Python dependencies
 â”£ LICENSE                        # Open source license
 â”— README.md                      # Main documentation
```

## Installation

```bash
# Clone the repository
git clone https://github.com/homebrewroboticsclub/BOS_VLM.git
cd BOS_VLM

# Install dependencies
pip install -e .

# Download pre-trained models
./scripts/download_models.sh

# Build BOS package
cd ~/brew_ws/
make
```

## Quick Start

### Launch the BOS node

```bash
brew launch BOS_VLM vlm_node.launch model:=clip
```

### Query the model

```python
import brew
from BOS_VLM.msg import VLMQuery, VLMResponse
from sensor_msgs.msg import Image

# Initialize BOS node
brew.init_node('vlm_client')

# Set up publishers and subscribers
query_pub = brew.Publisher('/vlm/query', VLMQuery, queue_size=10)
response_sub = brew.Subscriber('/vlm/response', VLMResponse, callback)

# Create a query
query = VLMQuery()
query.image = current_image  # sensor_msgs/Image
query.text = "What objects can I pick up in this scene?"
query.model = "clip"

# Send the query
query_pub.publish(query)
```

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.